![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# 🚀 Project Title

> SightMate – AI Companion for the Visually Impaired

---

## 📌 Problem Statement

**Problem Statement 1 – Weave AI Magic With Groq**

---

## 🎯 Objective

SightMate is a powerful, AI-enhanced platform designed to assist ***visually impaired*** individuals in navigating daily life with greater independence, awareness, and safety. From real-time road guidance and document reading to emergency assistance and voice-controlled interactions, SightMate is a comprehensive companion built using modern AI models and tools powered by Groq, FastAPI, and open-source ecosystems.

---

## 🧠 Team & Approach

### Team Name:  
`Lucid Reapers`

### Team Members:  
- Mitesh Kumavat [[Github](https://github.com/mitesh-kumavat) | [LinkedIn](https://linkedin.com/in/mitesh-kumavat) | Backend Developer]  
- Shivangi Gohel [[Github](https://github.com/shivangi-gohel) | [LinkedIn](https://www.linkedin.com/in/shivangi-gohel-54339b330/) | Frontend Developer]  

### Your Approach:  
- Blind people face several challanges in daily life thus it needs to be resolved  
-
-

---

## 🛠️ Tech Stack

### Core Technologies Used:
- Frontend: Next.js, Tailwind css, ShadCn, motion
- Backend: Python, FastAPI
- Database: SQLite
- APIs: 
- Hosting: Vercel + Render(backend)

### Sponsor Technologies Used (if any):
- [✅] **Groq:** _How you used Groq_  
- [ ] **Monad:** _Your blockchain implementation_  
- [ ] **Fluvio:** _Real-time data handling_  
- [ ] **Base:** _AgentKit / OnchainKit / Smart Wallet usage_  
- [ ] **Screenpipe:** _Screen-based analytics or workflows_  
- [ ] **Stellar:** _Payments, identity, or token usage_
*(Mark with ✅ if completed)*
---

# ✨ Key Features


### 🛣️ Real-Time Scene Monitoring & Road Guidance

- Continuously captures photos from the user's camera.
- Uses AI to interpret surroundings in real-time.
- Describes obstacles, traffic situations, and environments with speech output.
- Designed to guide users walking on roads or in unfamiliar spaces.

### 🔊 Voice Interaction with Audio Feedback

- Uses speech recognition for hands-free interaction.
- Outputs all responses using realistic Text-to-Speech (TTS).
- Powered by Groq's TTS for natural, expressive voices.
- Allows full audio navigation for non-screen interaction.

### 📰 Daily News Reader

- Fetches real-time top news from reliable public APIs.
- Uses LLMs to summarize news into short, digestible content.
- Speaks out the summarized news clearly and concisely.

### 📄 Document Reader

- Users can show printed or handwritten documents to the camera.
- LLM Extracts and summarizes the content.
- Reads out the summary to the user using TTS.

### 💰 Indian Currency Recognition

- Recognizes Indian currency notes via camera.
- Announces the denomination out loud to the user.
- Count the total sum of the money

### 🎨 Scene-to-Art Description

- Describes the camera’s view in an artistic or imaginative manner.
- Helps the user visualize surroundings creatively.
- Can serve both practical and entertainment purposes.

### 🔁 General Voice Commands & Knowledge Assistant

- Allows users to ask general questions (e.g., time, weather, facts).
- Powered by Groq's high-speed inference of Mixtral LLM.
- Quick, natural voice interaction for everyday queries.

> Add images, GIFs, or screenshots if helpful!

---

## 📽️ Demo & Deliverables

- **Demo Video Link:** [Paste YouTube or Loom link here]  
- **Pitch Deck / PPT Link:** [Paste Google Slides / PDF link here]  

---

## ✅ Tasks & Bonus Checklist

- [ ] **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** (Details in Participant Manual)  
- [ ] **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)**  (Details in Participant Manual)
- [✅] **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**  (Details in Participant Manual)

*(Mark with ✅ if completed)*

---

## 🧪 How to Run the Project

### Requirements:
- Node.js and Python  .
- API Keys : Groq
- Follow this for env setup: [.env.sample](./.env.sample)

### Local Setup:

#### Backend setup
```bash
# Clone the repo
git clone https://github.com/mitesh-kumavat/sightmate

# Install backend dependencies
cd sightmate
pip install -r requirements.txt
# Run the python server:
uvicorn app.main:app --reload
```

#### Frontend setup
- make sure you open another terminal so that frontend run sepratly
```bash
# Install frontend dependencies
cd frontend
npm install

# Start frontend server
npm run dev
```

---

## 🧬 Future Scope

- 👓 Smart physical glasses with all the features 
- 🔍 Object Finder (e.g., *“Find my glasses”*)
- 🧭 Indoor Navigation via `Beacons`
- 🧑‍🤝‍🧑 Community SOS Dashboard for caretakers
- 🌐 Multilingual Interface with Translation
- 📱 Android App with Voice Wake Word Integrationy  

---

## 📎 Resources / Credits

- APIs or datasets used  
- Open source libraries or tools referenced  
- Acknowledgements  

---

## 🏁 Final Words

SightMate aims to redefine independence for the blind through a blend of real-time AI, vision, and voice technologies — all in one seamless platform. By combining Groq's ultra-fast inference capabilities, open-source models, and a user-centric design, this project brings practical, scalable, and life-saving features to those who need them most.

---